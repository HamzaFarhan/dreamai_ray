{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF APP\n",
    "\n",
    "> Functions distributed PDF information extraction application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp pdf.app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from dreamai_ray.imports import *\n",
    "from dreamai_ray.utils import *\n",
    "from dreamai_ray.pdf.core import *\n",
    "from dreamai_ray.pdf.extract import *\n",
    "from dreamai_ray.pdf.ner import *\n",
    "from dreamai_ray.pdf.df import *\n",
    "from dreamai_ray import redis_kv_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SegsPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"HamzaFarhan/PDFSegs\",\n",
    "        thresh=0.6,\n",
    "        write=False,\n",
    "        device=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        device = default_device() if device is None else device\n",
    "        self.thresh = thresh\n",
    "        self.model = load_segs_model(model_name, device=device)\n",
    "        self.write = write\n",
    "\n",
    "    def __call__(self, df):\n",
    "        msg.info(f\"LEN SEGS DF: {len(df)}\", spaced=True)\n",
    "        df[[\"segs\", \"classes\", \"probs\"]] = df.apply(\n",
    "            lambda x: write_df_segs(\n",
    "                x,\n",
    "                self.model,\n",
    "                thresh=self.thresh,\n",
    "                write=self.write,\n",
    "            ),\n",
    "            axis=1,\n",
    "            result_type=\"expand\",\n",
    "        )\n",
    "        return df\n",
    "\n",
    "\n",
    "class NERPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ner_roles=True,\n",
    "        device=None,\n",
    "        task_id=None,\n",
    "        redis_host=\"127.0.0.1\",\n",
    "        redis_port=6379,\n",
    "    ):\n",
    "        device = default_device() if device is None else device\n",
    "        # msg.info(f\"NER DEVICE: {device}\", spaced=True)\n",
    "        self.tner = load_ner_model(device=device)\n",
    "        self.jner = load_job_model(device=device)\n",
    "        if ner_roles:\n",
    "            self.work_ner_dict = {\"company\": \"\", \"role\": \"\", \"date\": \"\"}\n",
    "        else:\n",
    "            self.work_ner_dict = {\"company\": \"\", \"date\": \"\"}\n",
    "        self.task_id = task_id\n",
    "        self.kv_store = redis_kv_store.KeyValueStore(\n",
    "            redis_host=redis_host, redis_port=redis_port\n",
    "        )\n",
    "\n",
    "    def __call__(self, df):\n",
    "        msg.info(f\"LEN NER DF: {len(df)}\", spaced=True)\n",
    "        df = df.apply(\n",
    "            lambda x: write_df_ner(\n",
    "                x,\n",
    "                tner=self.tner,\n",
    "                jner=self.jner,\n",
    "                work_ner_dict=self.work_ner_dict,\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        if self.task_id is not None and self.kv_store is not None:\n",
    "            for _ in range(len(df)):\n",
    "                update_task_progress(self.task_id, self.kv_store)\n",
    "        return df\n",
    "\n",
    "\n",
    "class EmsPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"HamzaFarhan/PDFSegs\",\n",
    "        device=\"cpu\",\n",
    "        task_id=None,\n",
    "        redis_host=\"127.0.0.1\",\n",
    "        redis_port=6379,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        device = default_device() if device is None else device\n",
    "        self.model = load_ems_model(model_name, device=device)\n",
    "        self.task_id = task_id\n",
    "        self.kv_store = redis_kv_store.KeyValueStore(\n",
    "            redis_host=redis_host, redis_port=redis_port\n",
    "        )\n",
    "\n",
    "    def __call__(self, df):\n",
    "        msg.info(f\"LEN EMS DF: {len(df)}\", spaced=True)\n",
    "        df = df.apply(lambda x: write_df_ems(x, self.model), axis=1)\n",
    "        if self.task_id is not None and self.kv_store is not None:\n",
    "            for _ in range(len(df)):\n",
    "                update_task_progress(self.task_id, self.kv_store)\n",
    "        return df\n",
    "\n",
    "\n",
    "def pdf_pipeline(params):\n",
    "    try:\n",
    "        task_id = params[\"task_id\"]\n",
    "        data_path = params[\"data_path\"]\n",
    "        segs_folder = params[\"segs_folder\"]\n",
    "        ems_folder = params[\"ems_folder\"]\n",
    "        segs_params = params[\"segs_params\"]\n",
    "        ems_params = params[\"ems_params\"]\n",
    "        num_blocks = params[\"num_blocks\"]\n",
    "        blocks_per_window = params[\"blocks_per_window\"]\n",
    "        redis_host = params.get(\"redis_host\", \"127.0.0.1\")\n",
    "        redis_port = params.get(\"redis_port\", 6379)\n",
    "        do_segs = params.get(\"do_segs\", True)\n",
    "        do_ner = params.get(\"do_ner\", False)\n",
    "        if do_segs:\n",
    "            segs_params[\"fn_constructor_kwargs\"][\"write\"] = True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in params: {e}.\\nParams: {params}\")\n",
    "    try:\n",
    "        kv_store = redis_kv_store.KeyValueStore(\n",
    "            redis_host=redis_host, redis_port=redis_port\n",
    "        )\n",
    "        ems_params[\"fn_constructor_kwargs\"][\"task_id\"] = task_id\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in connecting to redis: {e}.\\nParams: {params}\")\n",
    "\n",
    "    try:\n",
    "        # segs_folder = Path(task_id) / Path(segs_folder).name\n",
    "        # ems_folder = Path(task_id) / Path(ems_folder).name\n",
    "        task_folder = Path(f\"/tmp/{task_id}\")\n",
    "        os.makedirs(task_folder, exist_ok=True)\n",
    "        local_segs_folder = get_local_path(segs_folder, task_folder)\n",
    "        local_ems_folder = get_local_path(ems_folder, task_folder)\n",
    "        df = create_pdf_df(\n",
    "            data_path, segs_folder=local_segs_folder, ems_folder=local_ems_folder\n",
    "        )\n",
    "        init_task_progress(task_id, kv_store, len(df))\n",
    "        ds = rd.from_modin(df)\n",
    "        if num_blocks is not None:\n",
    "            num_blocks = min(num_blocks, len(df))\n",
    "            ds = ds.repartition(num_blocks)\n",
    "            if blocks_per_window is not None:\n",
    "                ds = ds.window(blocks_per_window=blocks_per_window)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in create_pdf_df: {e}.\")\n",
    "    try:\n",
    "        ds = ds.map_batches(\n",
    "            extract_df_text, batch_size=params[\"segs_params\"][\"batch_size\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in extract_df_text: {e}.\")\n",
    "\n",
    "    if do_segs:\n",
    "        try:\n",
    "            ds = ds.map_batches(\n",
    "                SegsPredictor,\n",
    "                **segs_params,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error in SegsPredictor: {e}.\\nseg_params: {segs_params}\")\n",
    "    try:\n",
    "        ds = ds.map_batches(\n",
    "            EmsPredictor,\n",
    "            **ems_params,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in EmsPredictor: {e}.\\nems_params: {ems_params}\")\n",
    "    ds = str(write_ds(ds, task_folder / \"pdf_preds.parquet\"))\n",
    "    if is_bucket(segs_folder):\n",
    "        # bucket = Path(segs_folder).parent\n",
    "        bucket_copy(local_segs_folder, segs_folder, only_new=False)\n",
    "    if is_bucket(ems_folder):\n",
    "        # bucket = Path(ems_folder).parent\n",
    "        bucket_move(local_ems_folder, ems_folder)\n",
    "    shutil.rmtree(ds)\n",
    "    if not do_ner:\n",
    "        shutil.rmtree(task_folder)\n",
    "    return {\"pipeline_result\": \"SUCCESS\"}\n",
    "\n",
    "\n",
    "def ner_pipeline(params):\n",
    "    try:\n",
    "        task_id_ner = params[\"task_id_ner\"]\n",
    "        task_id = params[\"task_id\"]\n",
    "        data_path = params[\"data_path\"]\n",
    "        segs_folder = params[\"segs_folder\"]\n",
    "        ner_params = params[\"ner_params\"]\n",
    "        num_blocks = params[\"num_blocks\"]\n",
    "        redis_host = params.get(\"redis_host\", \"127.0.0.1\")\n",
    "        redis_port = params.get(\"redis_port\", 6379)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in params: {e}.\\nParams: {params}\")\n",
    "    try:\n",
    "        kv_store = redis_kv_store.KeyValueStore(\n",
    "            redis_host=redis_host, redis_port=redis_port\n",
    "        )\n",
    "        ner_params[\"fn_constructor_kwargs\"][\"task_id\"] = task_id_ner\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in connecting to redis: {e}.\\nParams: {params}\")\n",
    "    try:\n",
    "        task_folder = Path(f\"/tmp/{task_id}\")\n",
    "        os.makedirs(task_folder, exist_ok=True)\n",
    "        local_segs_folder = get_local_path(segs_folder, task_folder)\n",
    "        # msg.info(f\"Local_segs_folder: {local_segs_folder}\", spaced=True)\n",
    "        df = create_ner_df(data_path, segs_folder=local_segs_folder)\n",
    "        init_task_progress(task_id_ner, kv_store, len(df))\n",
    "        ds = rd.from_modin(df)\n",
    "        if num_blocks is not None:\n",
    "            num_blocks = min(num_blocks, len(df))\n",
    "            ds = ds.repartition(num_blocks)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in create_ner_df: {e}.\")\n",
    "\n",
    "    try:\n",
    "        ds = ds.map_batches(\n",
    "            NERPredictor,\n",
    "            **ner_params,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in NERPredictor: {e}.\\nner_params: {ner_params}\")\n",
    "    ds = str(write_ds(ds, task_folder / \"ner_preds.parquet\"))\n",
    "    if is_bucket(segs_folder):\n",
    "        bucket_copy(local_segs_folder, segs_folder, only_new=True)\n",
    "    shutil.rmtree(task_folder)\n",
    "    return {\"ner_pipeline_result\": \"SUCCESS\"}\n",
    "\n",
    "\n",
    "def pipeline_params(\n",
    "    data_path=\"\",\n",
    "    segs_folder=\"pdf_segs\",\n",
    "    ems_folder=\"pdf_ems\",\n",
    "    segs_model=\"HamzaFarhan/PDFSegs\",\n",
    "    ems_model=\"HamzaFarhan/PDFSegs\",\n",
    "    num_gpus=1,\n",
    "    num_blocks=None,\n",
    "    batch_sizes=[8, 8, 8],\n",
    "    workers=[[3, 4], [3, 4], [3, 4]],\n",
    "    do_segs=True,\n",
    "    do_ner=False,\n",
    "    redis_host=\"127.0.0.1\",\n",
    "    redis_port=6379,\n",
    "    **kwargs,\n",
    "):\n",
    "    if not is_list(batch_sizes):\n",
    "        batch_sizes = [batch_sizes]\n",
    "    if not is_list(workers[0]):\n",
    "        workers = [workers]\n",
    "    batch_sizes += [batch_sizes[0]] * (2 - len(batch_sizes))\n",
    "    workers += [workers[0]] * (2 - len(workers))\n",
    "    try:\n",
    "        max_workers = workers[1][1]\n",
    "        if do_segs:\n",
    "            max_workers += workers[0][1]\n",
    "            # if do_ner:\n",
    "            # max_workers += workers[1][1]\n",
    "        num_gpus = num_gpus / max_workers\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid workers: {e}\")\n",
    "    try:\n",
    "        params = {\n",
    "            \"data_path\": data_path,\n",
    "            \"segs_folder\": segs_folder,\n",
    "            \"ems_folder\": ems_folder,\n",
    "            \"num_blocks\": num_blocks,\n",
    "            \"blocks_per_window\": None,\n",
    "            \"do_segs\": do_segs,\n",
    "            \"do_ner\": do_ner,\n",
    "            \"redis_host\": redis_host,\n",
    "            \"redis_port\": redis_port,\n",
    "            \"segs_params\": dict(\n",
    "                fn_constructor_kwargs=dict(\n",
    "                    model_name=segs_model,\n",
    "                    device=None,\n",
    "                ),\n",
    "                batch_size=batch_sizes[0],\n",
    "                compute=rd.ActorPoolStrategy(\n",
    "                    min_size=workers[0][0], max_size=workers[0][1]\n",
    "                ),\n",
    "                num_gpus=num_gpus,\n",
    "            ),\n",
    "            \"ems_params\": dict(\n",
    "                fn_constructor_kwargs=dict(\n",
    "                    model_name=ems_model,\n",
    "                    device=None,\n",
    "                    redis_host=redis_host,\n",
    "                    redis_port=redis_port,\n",
    "                ),\n",
    "                batch_size=batch_sizes[1],\n",
    "                compute=rd.ActorPoolStrategy(\n",
    "                    min_size=workers[1][0], max_size=workers[1][1]\n",
    "                ),\n",
    "                num_gpus=num_gpus,\n",
    "            ),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid params: {e}.\\nParams so far: {locals()}\")\n",
    "    return params\n",
    "\n",
    "\n",
    "def ner_pipeline_params(\n",
    "    data_path=\"\",\n",
    "    segs_folder=\"pdf_segs\",\n",
    "    num_gpus=1,\n",
    "    num_blocks=None,\n",
    "    ner_batch_size=8,\n",
    "    ner_workers=[[3, 4]],\n",
    "    redis_host=\"127.0.0.1\",\n",
    "    redis_port=6379,\n",
    "    # do_ner=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    try:\n",
    "        if is_list(ner_batch_size):\n",
    "            ner_batch_size = ner_batch_size[0]\n",
    "        if not is_list(ner_workers[0]):\n",
    "            ner_workers = [ner_workers]\n",
    "        min_workers, max_workers = ner_workers[0]\n",
    "        num_gpus = num_gpus / max_workers\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid workers: {e}\")\n",
    "    try:\n",
    "        params = {\n",
    "            \"data_path\": data_path,\n",
    "            \"segs_folder\": segs_folder,\n",
    "            \"num_blocks\": num_blocks,\n",
    "            \"blocks_per_window\": None,\n",
    "            \"redis_host\": redis_host,\n",
    "            \"redis_port\": redis_port,\n",
    "            \"ner_params\": dict(\n",
    "                fn_constructor_kwargs=dict(\n",
    "                    device=None,\n",
    "                    redis_host=redis_host,\n",
    "                    redis_port=redis_port,\n",
    "                ),\n",
    "                batch_size=ner_batch_size,\n",
    "                compute=rd.ActorPoolStrategy(\n",
    "                    min_size=min_workers, max_size=max_workers\n",
    "                ),\n",
    "                num_gpus=num_gpus,\n",
    "            ),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid params: {e}.\\nParams so far: {locals()}\")\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
