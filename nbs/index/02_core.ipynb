{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Core functionality for indexing and searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp index.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from dreamai_ray.imports import *\n",
    "from dreamai_ray.utils import *\n",
    "from dreamai_ray.mapper import *\n",
    "from dreamai_ray.index.utils import *\n",
    "from dreamai_ray.index.df import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class write_index_cb(Callback):\n",
    "    \"A `Callback` to write the index to disk.\"\n",
    "\n",
    "    def after_batch(self, cls, **kwargs):\n",
    "        cls.index = cls.udf_kwargs[\"index\"]\n",
    "        index_folder = cls.index_folder\n",
    "        os.makedirs(index_folder, exist_ok=True)\n",
    "        index_path = str(Path(index_folder) / f\"{cls.block_counter}_{cls.index.ntotal}.faiss\")\n",
    "        df_path = str(Path(index_folder) / f\"{cls.block_counter}.csv\")\n",
    "        if self.verbose and cls.verbose:\n",
    "            msg.info(f\"Writing Index to {index_path}\")\n",
    "            msg.info(f\"Index Size: {cls.index.ntotal}\")\n",
    "            msg.info(f\"Writing DF to {df_path}\")\n",
    "        faiss.write_index(cls.index, index_path)\n",
    "        kwargs[\"df\"].to_csv(df_path, index=False)\n",
    "\n",
    "\n",
    "class reset_index_cb(Callback):\n",
    "    \"A `Callback` to reset the index.\"\n",
    "\n",
    "    def after_batch(self, cls, **kwargs):\n",
    "        cls.index.reset()\n",
    "        if self.verbose and cls.verbose:\n",
    "            msg.info(f\"Index Size Post Reset: {cls.index.ntotal}\")\n",
    "        cls.udf_kwargs[\"index\"] = cls.index\n",
    "        cls.udf = partial(cls.udf, **cls.udf_kwargs)\n",
    "\n",
    "\n",
    "class IndexCreator(Mapper):\n",
    "    \"Creates indexes from embeddings.\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        index=None,\n",
    "        index_dim=3,  # The dimension of the index.\n",
    "        index_folder=\"indexes\",  # The folder to write the index to.\n",
    "        ems_col=\"embedding\",  # The column to use to create the index.\n",
    "        udf=df_to_index,  # The function to use to create the index.\n",
    "        cbs=[write_index_cb, reset_index_cb],  # The `Callback`s to use.\n",
    "        verbose=True,  # Whether to print out information.\n",
    "        udf_verbose=False,  # Whether to print out information in the udf.\n",
    "        udf_kwargs={},  # Additional kwargs to pass to the udf.\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.index_folder = index_folder\n",
    "        if index is None:\n",
    "            self.index = create_index(index_dim)\n",
    "        else:\n",
    "            self.index = index\n",
    "        udf_kwargs[\"index\"] = self.index\n",
    "        udf_kwargs[\"ems_col\"] = ems_col\n",
    "        udf_kwargs[\"verbose\"] = udf_verbose\n",
    "        self.verbose = verbose\n",
    "        super().__init__(**locals_to_params(locals()))\n",
    "\n",
    "\n",
    "def create_indexes(\n",
    "    ems_folder=\"embeddings\",  # The folder containing the embeddings.\n",
    "    ems_col=\"embedding\",  # The column to use to create the index.\n",
    "    block_size=40000,  # The number of embeddings per index. if None, all embeddings will be used.\n",
    "    index_dim=768,  # The dimension of the index.\n",
    "    index_folder=\"indexes\",  # The folder to write the index to.\n",
    "    udf=df_to_index,  # The function to use to create the index.\n",
    "    cbs=[write_index_cb, reset_index_cb],  # The `Callback`s to use.\n",
    "    verbose=True,  # Whether to print out information.\n",
    "    udf_verbose=False,  # Whether to print out information in the udf.\n",
    "    udf_kwargs={},  # Additional kwargs to pass to the udf.\n",
    "    task_id=gen_random_string(16),  # The task id to use.\n",
    "    **kwargs,\n",
    "):\n",
    "    \"Function to create indexes from embeddings.\"\n",
    "\n",
    "    task_folder = f\"/tmp/{task_id}\"\n",
    "    t1 = time()\n",
    "    ems_folder, _ = handle_input_path(ems_folder, local_path=task_folder)\n",
    "    t2 = time()\n",
    "    if verbose:\n",
    "        msg.info(f\"Time taken to download embeddings: {t2-t1:.2f} seconds.\", spaced=True)\n",
    "    # index_folder, index_bucket = get_local_path(index_folder, local_path=local_index_folder)\n",
    "    index_folder, index_bucket = get_local_path(index_folder, local_path=task_folder)\n",
    "    bucket_indexes = max(bucket_count(index_bucket), 0) // 2\n",
    "    if verbose:\n",
    "        msg.info(f\"Bucket Indexes: {bucket_indexes}\")\n",
    "    cbs = [block_counter_cb(bucket_indexes)] + cbs\n",
    "    m = IndexCreator(\n",
    "        **locals_to_params(\n",
    "            locals(),\n",
    "            omit=[\"ems_folder\", \"ems_bucket\", \"index_bucket\", \"block_size\"],\n",
    "        ),\n",
    "    )\n",
    "    em_files = sorted(\n",
    "        get_files(ems_folder, extensions=[\".json\"], make_str=True),\n",
    "        key=lambda x: int(Path(x).stem.split(\"_\")[-1]),\n",
    "    )\n",
    "    # ems = [json.load(open(em_file))[\"embedding\"] for em_file in em_files]\n",
    "    df = pd.DataFrame({ems_col: em_files})\n",
    "    if verbose:\n",
    "        msg.info(f\"Embeddings DF created of length: {len(df)}\")\n",
    "    if block_size is None:\n",
    "        block_size = len(df)\n",
    "    for i in range(0, len(df), block_size):\n",
    "        df_block = df.iloc[i : i + block_size]\n",
    "        df_block = m(df_block).reset_index(drop=True)\n",
    "        # df_path = str(Path(index_folder) / f\"{m.block_counter}.csv\")\n",
    "        # df_block.to_csv(df_path, index=False)\n",
    "    bucket_up(index_folder, index_bucket, only_new=False)\n",
    "    shutil.rmtree(task_folder)\n",
    "    return df\n",
    "\n",
    "\n",
    "def search_indexes(\n",
    "    ems,  # The embedding to search. Can be pre-loaded or a path to a json file.\n",
    "    index_folder,  # The remote folder containing the indexes.\n",
    "    local_index_folder=\"/media/hamza/data2/faiss_data/saved_indexes\",  # The local folder containing the indexes. Not required if `index_folder` is local.\n",
    "    k=2,  # The number of nearest neighbors to return.\n",
    "    verbose=True,  # Whether to print out information.\n",
    "    task_id=gen_random_string(16),  # The task id to use.\n",
    "):\n",
    "    \"Function to search an embedding against indexes.\"\n",
    "\n",
    "    task_folder = f\"/tmp/{task_id}\"\n",
    "    # if os.path.exists(local_index_folder):\n",
    "    # index_folder = local_index_folder\n",
    "    # else:\n",
    "    if local_index_folder is None:\n",
    "        index_folder, _ = handle_input_path(\n",
    "            index_folder, local_path=local_index_folder, task_id=task_id\n",
    "        )\n",
    "    else:\n",
    "        pre_index_folder, _ = get_local_path(index_folder, local_path=local_index_folder)\n",
    "        if os.path.exists(pre_index_folder):\n",
    "            if verbose:\n",
    "                msg.info(f\"Cached Index Folder: {pre_index_folder}\", spaced=True)\n",
    "            index_folder = pre_index_folder\n",
    "        else:\n",
    "            index_folder, _ = handle_input_path(\n",
    "                index_folder, local_path=local_index_folder, task_id=task_id\n",
    "            )\n",
    "        \n",
    "    bucket_dl(ems, task_folder)\n",
    "    ems_file = get_files(task_folder, extensions=[\".json\"])[0]\n",
    "    with open(ems_file) as f:\n",
    "        ems = json.load(f)[\"embedding\"]\n",
    "    indexes = sorted(\n",
    "        get_files(index_folder, extensions=[\".faiss\"]),\n",
    "        key=lambda x: int(x.stem.split(\"_\")[0]),\n",
    "    )\n",
    "    if not os.path.exists(index_folder) or len(indexes) == 0:\n",
    "        raise Exception(\n",
    "            f\"No indexes found in '{index_folder}' folder. Please create indexes first.\"\n",
    "        )\n",
    "    qdf = pd.DataFrame(\n",
    "        {\n",
    "            \"index\": indexes,\n",
    "            \"embedding\": [ems] * len(indexes),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    qdf = qdf.apply(lambda x: df_index_search(x, k=k, verbose=verbose), axis=1)\n",
    "    res = index_heap(qdf, k=k, verbose=verbose, with_offset=True)\n",
    "    dfs = sorted(get_files(index_folder, extensions=[\".csv\"]), key=lambda x: int(x.stem))\n",
    "    print(dfs)\n",
    "    df = pd.concat([pd.read_csv(df) for df in dfs]).reset_index(drop=True)\n",
    "    res[\"meta_data\"] = df.iloc[res[\"ids\"][0]].to_dict(orient=\"records\")\n",
    "    shutil.rmtree(task_folder)\n",
    "    return res, qdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "np.random.seed(42)\n",
    "data_path = Path(\"/media/hamza/data2/faiss_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | eval: false\n",
    "\n",
    "# data_path = Path(\"\")\n",
    "# ems_folder = data_path / \"ems\"\n",
    "# index_folder = data_path / \"indexes\"\n",
    "# num_ems = 50\n",
    "# block_size = 10\n",
    "# ems_dim = 768\n",
    "# random_ems(num_ems=num_ems, ems_dim=ems_dim, ems_folder=ems_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "bucket = \"gs://gcsfuse-talentnet-dev\"\n",
    "\n",
    "ems_folder = f\"{bucket}/ems_1_1\"\n",
    "index_folder = f\"{bucket}/indexes_1\"\n",
    "ems_dim = 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;4mℹ Downloading gs://gcsfuse-talentnet-dev/ems_1_1 to\n",
      "/tmp/e324b71dd9114694/ems_1_1.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_1.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_10.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_11.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_12.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_14.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_15.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_13.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_16.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_2.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_3.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_4.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_5.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_6.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_7.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_8.json...\n",
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_9.json...\n",
      "- [16/16 files][267.4 KiB/267.4 KiB] 100% Done                                  \n",
      "Operation completed over 16 objects/267.4 KiB.                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;4mℹ Time taken to download embeddings: 2.06 seconds.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Bucket Indexes: 0\u001b[0m\n",
      "\u001b[38;5;4mℹ Embeddings DF created of length: 16\u001b[0m\n",
      "\n",
      "\u001b[38;5;4mℹ DF BATCH SIZE: 16\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[38;5;4mℹ Uploading /tmp/e324b71dd9114694/indexes_1 to\n",
      "gs://gcsfuse-talentnet-dev/indexes_1.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/e324b71dd9114694/indexes_1/1_16.faiss [Content-Type=application/octet-stream]...\n",
      "Copying file:///tmp/e324b71dd9114694/indexes_1/1.csv [Content-Type=text/csv]... \n",
      "- [2/2 files][ 49.3 KiB/ 49.3 KiB] 100% Done                                    \n",
      "Operation completed over 2 objects/49.3 KiB.                                     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_2.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_3.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_4.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_5.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           embedding\n",
       "0  /tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_1.json\n",
       "1  /tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_2.json\n",
       "2  /tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_3.json\n",
       "3  /tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_4.json\n",
       "4  /tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_5.json"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "ems_df = create_indexes(\n",
    "    ems_folder=ems_folder,\n",
    "    index_folder=index_folder,\n",
    "    index_dim=ems_dim,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "ems_df[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;4mℹ Downloading gs://gcsfuse-talentnet-dev/indexes_1 to\n",
      "/media/hamza/data2/faiss_data/saved_indexes/indexes_1.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://gcsfuse-talentnet-dev/indexes_1/1.csv...\n",
      "Copying gs://gcsfuse-talentnet-dev/indexes_1/1_16.faiss...                      \n",
      "/ [2/2 files][ 49.3 KiB/ 49.3 KiB] 100% Done                                    \n",
      "Operation completed over 2 objects/49.3 KiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;4mℹ Downloading\n",
      "gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_10.json\n",
      "to /tmp/0683652a48da4a1c.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://gcsfuse-talentnet-dev/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_10.json...\n",
      "/ [0/1 files][    0.0 B/ 16.7 KiB]   0% Done                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Path('/media/hamza/data2/faiss_data/saved_indexes/indexes_1/1.csv')]\n",
      "\n",
      "\n",
      "Final Results:\n",
      "\tDistances: [[0.0, 0.9240111708641052, 1.0372934341430664, 1.101623296737671, 1.1049132347106934, 1.1570426225662231, 1.209057092666626, 1.2113628387451172, 1.2239317893981934, 1.2323083877563477]]\n",
      "\tIDs: [[9, 11, 8, 13, 14, 1, 3, 7, 12, 4]]\n",
      "\tMeta Data:\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_10.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_12.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_9.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_14.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_15.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_2.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_4.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_8.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_13.json'}\n",
      "\t\t{'embedding': '/tmp/e324b71dd9114694/ems_1_1/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_5.json'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ [1/1 files][ 16.7 KiB/ 16.7 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/16.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "qems = f\"{ems_folder}/resumes-4e2cdbeb-1e20-45ff-bded-a0a510350167_10.json\"\n",
    "res, qdf = search_indexes(\n",
    "    qems,\n",
    "    index_folder=index_folder,\n",
    "    k=10,\n",
    "    verbose=False,\n",
    ")\n",
    "print(f'\\n\\nFinal Results:\\n\\tDistances: {res[\"distances\"]}\\n\\tIDs: {res[\"ids\"]}')\n",
    "print(\"\\tMeta Data:\")\n",
    "for m in res[\"meta_data\"]:\n",
    "    print(f\"\\t\\t{m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# shutil.rmtree(index_folder, ignore_errors=True)\n",
    "# shutil.rmtree(ems_folder, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
