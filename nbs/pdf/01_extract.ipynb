{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract\n",
    "\n",
    "> Functions for segmenting and embedding PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp pdf.extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from dreamai_ray.imports import *\n",
    "from dreamai_ray.pdf.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def add_other_class(classes, other_class=\"Other\"):\n",
    "    # Add 'Other' class if not present\n",
    "    if other_class not in classes:\n",
    "        classes.append(other_class)\n",
    "    return classes\n",
    "\n",
    "\n",
    "def print_segments(segments: dict, limit: int = 10, width: int = 100):\n",
    "    for k, v in segments.items():\n",
    "        print(f\"{k}: {len(v)}\")\n",
    "        for s in v[:limit]:\n",
    "            print(\"\\t\", end=\"\")\n",
    "            pprint(s, width=width)\n",
    "            print()\n",
    "        print(\"-\" * (width + 4))\n",
    "\n",
    "\n",
    "def text_to_segments(\n",
    "    text,\n",
    "    segs_model,\n",
    "    thresh=0.6,\n",
    "    classes=[\"Work Experience\", \"Education\", \"Certifications\", \"Other\"],\n",
    "    other_class=\"Other\",\n",
    "):\n",
    "    classes = add_other_class(classes, other_class)\n",
    "    ot_id = classes.index(other_class)\n",
    "    preds = segs_model.predict(text).detach().cpu().numpy()\n",
    "    probs = segs_model.predict_proba(text).detach().cpu().numpy().max(1)\n",
    "    preds[probs < thresh] = ot_id\n",
    "    pred_classes = [classes[p] for p in preds]\n",
    "    segments = {pc: [] for pc in classes}\n",
    "    for pc, txt in zip(pred_classes, text):\n",
    "        if txt not in segments[pc]:\n",
    "            segments[pc].append(txt)\n",
    "    return segments, pred_classes, probs\n",
    "\n",
    "\n",
    "def text_to_ems(\n",
    "    df,\n",
    "    ems_model,\n",
    "    classes=[\"Work Experience\", \"Education\", \"Certifications\", \"Other\"],\n",
    "    other_class=\"Other\",\n",
    "):\n",
    "    classes = add_other_class(classes, other_class)\n",
    "    seg_ids = {c: i + 1 for i, c in enumerate(classes)}\n",
    "    fn = Path(df[\"path\"]).stem\n",
    "    ems_folder = Path(df[\"ems_folder\"])\n",
    "    os.makedirs(ems_folder, exist_ok=True)\n",
    "    ems_path = str(ems_folder / fn)\n",
    "    txt = df[\"text\"]\n",
    "    pred_classes = df.get(\"classes\", [\"\"] * len(txt))\n",
    "    if len(txt) == 0 or len(pred_classes) == 0:\n",
    "        return df\n",
    "    ems = ems_model.encode(txt).tolist()\n",
    "    for i, data in enumerate(zip(pred_classes, ems)):\n",
    "        pc, em = data\n",
    "        seg_id = seg_ids.get(pc, 0)\n",
    "        if seg_id == 0:\n",
    "            seg = \"\"\n",
    "        else:\n",
    "            seg = f\"_{seg_id}\"\n",
    "        jf = ems_path + f\"{seg}_{i+1}.json\"\n",
    "        em_dict = {\"id\": fn, \"embedding\": em}\n",
    "        with open(jf, \"w\") as f:\n",
    "            json.dump(em_dict, f)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_segs_model(model_name=\"HamzaFarhan/PDFSegs\", device=\"cpu\"):\n",
    "    return SetFitModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "\n",
    "def load_ems_model(model_name=\"HamzaFarhan/PDFSegs\", device=\"cpu\"):\n",
    "    return SentenceTransformer(model_name, device=device)\n",
    "\n",
    "\n",
    "def write_segments(\n",
    "    segs_model,\n",
    "    data_path,\n",
    "    output_path=\"pdf_segments\",\n",
    "    n_lines=3,\n",
    "    classes=[\"Work Experience\", \"Education\", \"Certifications\", \"Other\"],\n",
    "    other_class=\"Other\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts text from PDFs and writes segments to json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    segs_model : SetFitModel\n",
    "        SetFit model for segment classification.\n",
    "    data_path : Union[str, Path, List[Union[str, Path]]]\n",
    "        Path to PDFs. Can be a single file, a directory, or a list of files/directories.\n",
    "    output_path : Union[str, Path]\n",
    "        Folder to write json files. Defaults to 'pdf_segments'.\n",
    "    n_lines : int\n",
    "        Number of lines to group together when extracting text from PDFs.\n",
    "    classes : List[str]\n",
    "        List of segment classes. Defaults to [\"Work Experience\", \"Education\", \"Certifications\", \"Other\"].\n",
    "    other_class : str\n",
    "        Name of the 'Other' class. Defaults to \"Other\".\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    pdfs = resolve_data_path(data_path)\n",
    "    text_dict = extract_text_dict(pdfs, n_lines=n_lines)\n",
    "    for file in pdfs:\n",
    "        try:\n",
    "            pdf_text = text_dict[str(file)]\n",
    "            (segments,) = text_to_segments(\n",
    "                pdf_text,\n",
    "                segs_model,\n",
    "                thresh=0.6,\n",
    "                classes=classes,\n",
    "                other_class=other_class,\n",
    "            )[0]\n",
    "            fn = (output_path / Path(file).stem).with_suffix(\".json\")\n",
    "            with open(fn, \"w\") as f:\n",
    "                json.dump(segments, f, indent=4)\n",
    "        except Exception as e:\n",
    "            msg.fail(f\"\\nCould not write segments for file: {str(file)}\", e)\n",
    "            # print(f\"\\nCould not write segments for file: {str(file)}\\n{e}\")\n",
    "\n",
    "\n",
    "def write_embeddings(\n",
    "    segs_model,\n",
    "    ems_model,\n",
    "    data_path,\n",
    "    output_path=\"pdf_ems\",\n",
    "    n_lines=3,\n",
    "    classes=[\"Work Experience\", \"Education\", \"Certifications\", \"Other\"],\n",
    "    other_class=\"Other\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts text from PDFs and writes embeddings to json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    segs_model : SetFitModel\n",
    "        SetFit model for segment classification.\n",
    "    ems_model : SentenceTransformer\n",
    "        SentenceTransformer model for embedding generation.\n",
    "    data_path : Union[str, Path, List[Union[str, Path]]]\n",
    "        Path to PDFs. Can be a single file, a directory, or a list of files/directories.\n",
    "    output_path : Union[str, Path]\n",
    "        Folder to write json files. Defaults to 'pdf_ems'.\n",
    "    n_lines : int\n",
    "        Number of lines to group together when extracting text from PDFs.\n",
    "    classes : List[str]\n",
    "        List of segment classes. Defaults to [\"Work Experience\", \"Education\", \"Certifications\", \"Other\"].\n",
    "    other_class : str\n",
    "        Name of the 'Other' class. Defaults to \"Other\".\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    classes = add_other_class(classes, other_class)\n",
    "    seg_ids = {c: i + 1 for i, c in enumerate(classes)}\n",
    "    # seg_ids = {\"Work Experience\": 1, \"Education\": 2, \"Certifications\": 3, \"Other\": 4}\n",
    "    pdfs = resolve_data_path(data_path)\n",
    "    text_dict = extract_text_dict(pdfs, n_lines=n_lines)\n",
    "    for file in pdfs:\n",
    "        # try:\n",
    "        fn = Path(file).stem\n",
    "        pdf_text = text_dict[str(file)]\n",
    "        ems = ems_model.encode(pdf_text)\n",
    "        pred_classes = text_to_segments(pdf_text, segs_model, classes=classes)[1]\n",
    "        for i, data in enumerate(zip(pred_classes, ems)):\n",
    "            pc, em = data\n",
    "            seg_id = seg_ids[pc]\n",
    "            jf = Path(output_path) / f\"{fn}_{seg_id}_{i+1}.json\"\n",
    "            em_dict = {\"id\": fn, \"embedding\": em.tolist()}\n",
    "            with open(jf, \"w\") as f:\n",
    "                json.dump(em_dict, f)\n",
    "            # except Exception as e:\n",
    "            # print(f\"\\nCould not write embeddings for {str(file)} - {e}\")\n",
    "            # msg.fail(f\"\\nCould not write embeddings for {str(file)}\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
